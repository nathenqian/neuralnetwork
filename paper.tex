\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{cvpr}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}

% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[breaklinks=true,bookmarks=false]{hyperref}

\cvprfinalcopy % *** Uncomment this line for the final submission

\def\cvprPaperID{****} % *** Enter the CVPR Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
%\ifcvprfinal\pagestyle{empty}\fi
\setcounter{page}{1}
\begin{document}

%%%%%%%%% TITLE
\title{ Chinese Poem Generator from Image}

\author{Kelei Cao\\
Tsinghua University \\
Computer Science \& Technology\\
{\tt\small ckl13@mails.tsinghua.edu.cn}
% For a paper whose authors are all at the same institution,
% omit the following lines up until the closing ``}''.
% Additional authors and addresses can be added with ``\and'',
% just like the second author.
% To save space, use either the email address or home page, not both
\and
Dichen Qian\\
Tsinghua University \\
Computer Science \& Technology\\
{\tt\small nathenqian@gmail.com}
}

\maketitle
%\thispagestyle{empty}

%%%%%%%%% ABSTRACT
\begin{abstract}
   	Chinese poem is very popular in China, for it's meaningful, convenience and gentle. It is very common in China that children can recite lot's of poems before primary school. 
	In Chinese parmary school, most Chinese teacher will teach children how to make sentences based on what they look. In addition, it's a way to cultivate the ability of communication for children.

	As the innovation of neural network has springed up these years, it's very interesting for computer whether they can make sentences based on an image. To make the thing even fantastic, we want to make the computer to generate the poem based on an specific image.
	
\end{abstract}

%%%%%%%%% BODY TEXT
\section{Introduction}
Deep learning has been proven in recent years to be an extremely useful tool for discriminative tasks. Through layers of linear transforms combined with nonlinearities, these systems learn to transform their input into an ideal representation across which we can draw clear decision boundaries. However It remains to be seen how this success might play out in the field of generative models. For computer, create the news based on the things it has learned must be the next generation.

In this paper, we will develop a generative models that can recognize the image, extract the feature in the image, and generate the poem based on the image. This is very basic for people, but hard for computer. In some sense, we want to explore the ability of computer.
%-------------------------------------------------------------------------
\subsection{Problem Statement}
This problem is a generative problem. The generative models should generate the poem that base on an specific image, which means that the poem should describe the image. For this purpose, the input image must contains some information and people can easily find out what the emotion it convey. The graph contains with different emotion is best for both people and computer to create the poem.

The output should be the beautiful poem that it's meaning is closed to this image.


\section{Related Work}
	Generating poem is popular in recent years, and there are many people research on it. On the other hand, explain image with sentence has also made great progress after deep learning widely used. Our approach is a combination of above two aspects, we select two methods that performing well in corresponding aspects, and try to get a fantastic result.
\section{Plan}
\subsection{Image to Sentence}
The first part of this problem is to generate a sentence based on the image. This sentence must contain the detail of this image, and it can describe this image.

The method we want to use here is proposed by Junhua Mao\footnote{ Junhua Mao, Wei Xu, Yi Yang, Jiang Wang, Alan L. Yuille : Explain Images with Multimodal Recurrent Neural Networks.}. We use a multimodal Recurrent Neural Networks (m-RNN) model to address both the task of generating novel sentences descriptions for images, and the task of image and sentence retrieval. The whole m-RNN architecture contains a language model part, an image part and a multimodal part. The language model part learns the dense feature embedding for each word in the dictionary and stores the semantic temporal context in recurrent layers. The image part contains a deep Convulutional Neural Network (CNN) \footnote{A. Krizhevsky, I. Sutskever, and G. E. Hinton. Imagenet classification with deep convolutional neural networks. In NIPS, pages 1097–1105, 2012.} which extracts image features.


\subsection{Translate and Extract}
Now we get the sentence, as to generate the meaningful poetry, we need to extract keywords from the sentences. We can use a translation process to deal the sentence and only use the words that appears in Chinese poetry dataset that we used in poem generator.

\subsubsection{Poem generator}
	The method we will use to generate poem is proposed by Mirella Lapata\footnote{Xingxing Zhang, Mirella Lapata : Chinese Poetry Generation with Recurrent Neural Networks.}.First, to create the first line of poem, We select all phrases corresponding to the users’s keywords and generate all possible combinations satisfying the tonal pattern constraints. We use a language model to rank the generated candidates and select the best ranked one as the first line in the poem. In implementation, we employ a character-based recurrent neural network language model.	And after that, we generate the rest poem lines with original lines. Convert lines $s_1$...$s_i$ into vectors $v_1$...$v_i$ with a convolutional sentence model (CSM). Next, a recurrent context model (RCM) takes $v_1$...$v_i$ as input and outputs $u_{j,i}$.Finally, $u_{1,i}$, $u_{2,i}$,...,$u_{j,i}$ and the first $j$ characters $w_1$...$w_j$ in line $s_{i+1}$ serve as input to a recurrent generation model (RGM) which estimates $P(w_{j+1} = k | w_{1:j} ,s_{1:i} )$ with $k\in V$, the probability distribution of the $j+1$ th character over all words in the vocabulary $V$.
%-------------------------------------------------------------------------
\section{Dataset}
The dataset we used is IAPR TC-12 dataset, which used to training the model that explain image. The other is Chinese Poetry corpus.
\section{Intermediate Result}
We have built a temporary framework and consulted one expert about this problem. The expert thought it's a very good idea and gave some advices.
We will soon try to use theano to implement our idea, for this week is the deadline of building a cpu.
\end{document}
